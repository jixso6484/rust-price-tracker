use std::time::{Duration, Instant, SystemTime};
use std::collections::HashMap;
use std::sync::Arc;
use headless_chrome::Tab;

// Infrastructure ì˜ì¡´ì„±
use crate::infrastruction::llm::llmRepository::LocalLLM;
use crate::infrastruction::browser::chromiumAdapter::ChromiumAdapter;
use crate::infrastruction::browser::models::{BrowserAction, BrowserState};
use crate::infrastruction::llm::models::MarketplaceStructure;
use crate::infrastruction::llm::response_parser::ResponseParser;
use crate::infrastruction::html::basic::{ParserFactory, HtmlParser};
use crate::infrastruction::database::models::Product;
// ì—ëŸ¬ ì²˜ë¦¬
use crate::components::error::error_cl::Result;

#[derive(Debug)]
pub struct CrawlingOrchestrator {
    /// ë…ë¦½ LLM ì¸ìŠ¤í„´ìŠ¤ 
    llm: Arc<LocalLLM>,
    
    /// ë…ë¦½ ë¸Œë¼ìš°ì € ì¸ìŠ¤í„´ìŠ¤ (ì‚¬ì´íŠ¸ë³„ ì „ìš©)
    browser: ChromiumAdapter,
    
    /// í˜„ì¬ í™œì„± íƒ­ (ì¬ì‚¬ìš©)
    current_tab: Option<Arc<Tab>>,
    
    parser : HtmlParser;

    // í˜„ì¬ í¬ë¡¤ë§ ì‚¬ì´íŠ¸
    pub site: String,
    //í¬ë¡¤ë§ ì—¬ë¶€
    pub crawling: bool,
}


#[derive(Debug)]s
struct monitoring{
    
    // ì‹¤í–‰ í†µê³„
    pub total_requests: u64,        // ì´ ìš”ì²­ ìˆ˜
    pub successful_requests: u64,   // ì„±ê³µí•œ ìš”ì²­ ìˆ˜
    pub failed_requests: u32,       // ì‹¤íŒ¨í•œ ìš”ì²­ ìˆ˜ (ê¸°ì¡´ crawling_fail)
    pub consecutive_failures: u32,  // ì—°ì† ì‹¤íŒ¨ ìˆ˜
    
    // ë°ì´í„° ìˆ˜ì§‘ í†µê³„ DB ì €ì¥ 
    pub items_collected: u64,       // ìˆ˜ì§‘ëœ ì•„ì´í…œ ìˆ˜
    pub duplicate_items: u64,       // ì¤‘ë³µ ì•„ì´í…œ ìˆ˜
    pub new_items: u64,            // ìƒˆë¡œìš´ ì•„ì´í…œ ìˆ˜
    
    // ì„±ëŠ¥ ë©”íŠ¸ë¦­
    pub avg_response_time: Duration,    // í‰ê·  ì‘ë‹µ ì‹œê°„
    pub requests_per_minute: f64,       // ë¶„ë‹¹ ìš”ì²­ ìˆ˜
    pub last_request_time: Option<Instant>, // ë§ˆì§€ë§‰ ìš”ì²­ ì‹œê°„
    
    // ì‹œê°„ ì •ë³´
    pub started_at: Option<SystemTime>,     // ì‹œì‘ ì‹œê°„
    pub last_success_at: Option<SystemTime>, // ë§ˆì§€ë§‰ ì„±ê³µ ì‹œê°„
    pub last_failure_at: Option<SystemTime>, // ë§ˆì§€ë§‰ ì‹¤íŒ¨ ì‹œê°„
    pub next_scheduled_at: Option<SystemTime>, // ë‹¤ìŒ ì˜ˆì • ì‹œê°„
    
    // ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
    pub memory_usage: u64,          // í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (bytes)
    pub peak_memory_usage: u64,     // ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    
    // ì—ëŸ¬ ì„¸ë¶€ ì •ë³´
    pub error_counts: HashMap<String, u32>, // ì—ëŸ¬ íƒ€ì…ë³„ ì¹´ìš´íŠ¸
    pub last_error: Option<String>,         // ë§ˆì§€ë§‰ ì—ëŸ¬ ë©”ì‹œì§€
    
    // ì„¤ì • ì •ë³´
    pub crawl_interval: Duration,   // í¬ë¡¤ë§ ê°„ê²©
    pub timeout: Duration,          // íƒ€ì„ì•„ì›ƒ
    pub max_retries: u32,          // ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    pub current_retry: u32,        // í˜„ì¬ ì¬ì‹œë„ ì¹´ìš´íŠ¸
}
impl CrawlingOrchestrator {
    /// ì‚¬ì´íŠ¸ë³„ ë…ë¦½ í¬ë¡¤ë§ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒì„±
    pub async fn new(site_url: &str) -> Result<Self> {
        let llm = LocalLLM::get_instance().await?;
        let browser = ChromiumAdapter::new().await?;
        let parsers = ParserFactory::new();

        
        println!("ğŸš€ ë…ë¦½ í¬ë¡¤ë§ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒì„±: {}", site_url);
        
        Ok(Self {
            llm,
            browser,
            current_tab: None,
            parsers,
            site: site_url.to_string(),
            crawling: false,
        })
    }
    
    /// í¬ë¡¤ë§ ì‹œì‘
    pub async fn start_crawling(&mut self) -> Result<()> {
        self.crawling = true;
        self.started_at = Some(SystemTime::now());
        println!("âœ… í¬ë¡¤ë§ ì‹œì‘: {}", self.site);
        Ok(())

        if self.crawling{}
    }
    
    /// í¬ë¡¤ë§ ì¤‘ì§€
    pub async fn stop_crawling(&mut self) {
        self.crawling = false;
        println!("ğŸ›‘ í¬ë¡¤ë§ ì¤‘ì§€: {}", self.site);
    }
}