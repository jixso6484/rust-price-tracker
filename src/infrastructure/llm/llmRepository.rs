use crate::components::error::error_cl::{Result, ErrorS};
use ort::{Environment, Session, SessionBuilder, Value}; // ONNX Runtime ì‚¬ìš©
use std::sync::Arc;
use tokio::sync::OnceCell;
use tiktoken_rs::CoreBPE;
use ndarray::Array2;

pub struct LocalLLM{
    environment: Option<Arc<Environment>>, // ONNX Environment
    model : Option<Session>, // ONNX ì„¸ì…˜
    tokenizer: CoreBPE,
    _config : ModelConfig, // _ prefixë¡œ unused ê²½ê³  ì œê±°
    model_loaded: bool,
}

#[derive(Debug)]
pub struct ModelConfig {
    pub _max_length: usize,     // _ prefixë¡œ unused ê²½ê³  ì œê±°
    pub _temperature: f32,      // _ prefixë¡œ unused ê²½ê³  ì œê±°  
    pub _top_p: f32,            // _ prefixë¡œ unused ê²½ê³  ì œê±°
    pub _vocab_size: usize,     // _ prefixë¡œ unused ê²½ê³  ì œê±°
}

impl Default for ModelConfig {
    fn default() -> Self {
        Self {
            _max_length: 32768,  // Qwen3 1.7B ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ (32K í† í°)
            _temperature: 0.7,
            _top_p: 0.9,
            _vocab_size: 151936, // Qwen3 vocabulary í¬ê¸°
        }
    }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
static LLM_INSTANCE: OnceCell<Arc<LocalLLM>> = OnceCell::const_new();

impl LocalLLM{
    pub async fn new()->Result<Self>{
        // ONNX ëª¨ë¸ íŒŒì¼ ì²´í¬
        let model_path = "src/infrastructure/llm/model_int8.onnx";
        
        let model_exists = std::path::Path::new(model_path).exists();
        let mut onnx_session = None;
        let mut onnx_environment = None;
        
        if model_exists {
            println!("ğŸ§  Qwen3 1.7B ONNX ëª¨ë¸ íŒŒì¼ ë°œê²¬!");
            
            // ONNX Environment ìƒì„±
            match Environment::builder()
                .with_name("qwen3_llm")
                .build() {
                Ok(env) => {
                    let env_arc = Arc::new(env);
                    println!("âœ… ONNX Environment ìƒì„± ì„±ê³µ");
                    
                    // SessionBuilder ìƒì„± ì‹œë„
                    match SessionBuilder::new(&env_arc) {
                        Ok(builder) => {
                            // ëª¨ë¸ íŒŒì¼ ë¡œë“œ
                            match builder.with_model_from_file(model_path) {
                                Ok(session) => {
                                    println!("âœ… ONNX ì„¸ì…˜ ìƒì„± ì„±ê³µ! ëª¨ë¸ ë¡œë“œ ì™„ë£Œ");
                                    onnx_environment = Some(env_arc);
                                    onnx_session = Some(session);
                                },
                                Err(e) => {
                                    println!("âŒ ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {}", e);
                                    println!("   íŒŒì¼ ê²½ë¡œ: {}", model_path);
                                    println!("   Mock ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.");
                                }
                            }
                        },
                        Err(e) => {
                            println!("âŒ SessionBuilder ìƒì„± ì‹¤íŒ¨: {}", e);
                            println!("   Mock ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.");
                        }
                    }
                },
                Err(e) => {
                    println!("âŒ ONNX Environment ìƒì„± ì‹¤íŒ¨: {}", e);
                    println!("   Mock ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.");
                }
            }
        } else {
            println!("âš ï¸ ONNX ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {}", model_path);
            println!("   Mock ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.");
        }
        
        let config = ModelConfig::default();
        
        // Qwen3 í† í¬ë‚˜ì´ì € ì´ˆê¸°í™” (GPT-4 í† í¬ë‚˜ì´ì € ëŒ€ì‹  ê·¼ì‚¬ì¹˜ ì‚¬ìš©)
        let tokenizer = tiktoken_rs::get_bpe_from_model("gpt-4")
            .map_err(|e| ErrorS::data("LocalLLM::new", format!("Failed to load tokenizer: {}", e)))?;
        
        let model_loaded = onnx_session.is_some();
        println!("âœ… LocalLLM ì´ˆê¸°í™” ì™„ë£Œ (ì‹¤ì œ ëª¨ë¸ ë¡œë“œ: {})", model_loaded);
        
        Ok(Self { 
            environment: onnx_environment,
            model: onnx_session,
            tokenizer, 
            _config: config, 
            model_loaded 
        })
    }
    

    // ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    pub async fn get_instance() -> Result<Arc<LocalLLM>> {
        LLM_INSTANCE.get_or_try_init(|| async {
            let llm = Self::new().await?;
            Ok(Arc::new(llm))
        }).await.cloned()
    }

    // Qwen3 1.7B í…ìŠ¤íŠ¸ ìƒì„± - ë‚´ì¥ LLMë§Œ ì‚¬ìš©
    pub async fn generate(&self, prompt: &str) -> Result<String> {
        if self.model_loaded {
            println!("ğŸ§  Qwen3 1.7B ëª¨ë¸ë¡œ ì¶”ë¡  ì¤‘...");
            self.run_inference(prompt).await
        } else {
            return Err(ErrorS::data("LocalLLM::generate", "ONNX ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”."));
        }
    }

    // ONNX ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰ (ìˆœìˆ˜ ì¶”ë¡ ë§Œ)
    async fn run_inference(&self, prompt: &str) -> Result<String> {
        let tokens = self.tokenize(prompt)?;
        
        // í† í° ê¸¸ì´ ì œí•œ (Qwen3 1.7BëŠ” 32K í† í°)
        let max_input_tokens = 16384; // ì ˆë°˜ë§Œ ì‚¬ìš© (ì¶œë ¥ ê³µê°„ í™•ë³´)
        let input_tokens = if tokens.len() > max_input_tokens {
            tokens[..max_input_tokens].to_vec()
        } else {
            tokens
        };
        
        println!("ğŸ“ ì…ë ¥ í† í° ìˆ˜: {}/{}", input_tokens.len(), max_input_tokens);
        
        // ONNX ëª¨ë¸ ì…ë ¥ ì¤€ë¹„
        let _input_ids = Array2::from_shape_vec((1, input_tokens.len()), input_tokens)
            .map_err(|e| ErrorS::data("LocalLLM::run_inference", format!("Failed to create input tensor: {}", e)))?;
        
        // ì‹¤ì œ ONNX ëª¨ë¸ ì¶”ë¡ 
        if let Some(ref session) = self.model {
            println!("ğŸ¤– ì‹¤ì œ ONNX ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰ ì¤‘...");
            
            // ONNX ëª¨ë¸ ì…ë ¥ ì¤€ë¹„ (input_ids)
            let input_ids = Array2::from_shape_vec((1, input_tokens.len()), input_tokens)
                .map_err(|e| ErrorS::data("LocalLLM::run_inference", format!("Failed to create input tensor: {}", e)))?;
            
            // ONNX ì…ë ¥ìœ¼ë¡œ ë³€í™˜
            match Value::from_array(session.allocator(), &input_ids) {
                Ok(input_value) => {
                    println!("ğŸ“Š ì…ë ¥ í…ì„œ ìƒì„± ì„±ê³µ");
                    
                    // ëª¨ë¸ ì‹¤í–‰
                    match session.run(vec![input_value]) {
                        Ok(outputs) => {
                            println!("âœ… ONNX ì¶”ë¡  ì„±ê³µ! ì¶œë ¥ ê°œìˆ˜: {}", outputs.len());
                            
                            if let Some(output_tensor) = outputs.get(0) {
                                match self.extract_output_tokens(output_tensor) {
                                    Ok(output_tokens) => {
                                        let response = self.detokenize(&output_tokens)?;
                                        println!("âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ: {} í† í°", output_tokens.len());
                                        return Ok(response);
                                    },
                                    Err(e) => {
                                        println!("âŒ ì¶œë ¥ í† í° ì¶”ì¶œ ì‹¤íŒ¨: {}", e);
                                    }
                                }
                            } else {
                                println!("âš ï¸ ì¶œë ¥ í…ì„œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤");
                            }
                        },
                        Err(e) => {
                            println!("âŒ ONNX ì¶”ë¡  ì‹¤íŒ¨: {}", e);
                            println!("   ì…ë ¥ shape: ({}, {})", 1, input_tokens.len());
                        }
                    }
                },
                Err(e) => {
                    println!("âŒ ì…ë ¥ í…ì„œ ìƒì„± ì‹¤íŒ¨: {}", e);
                }
            }
        } else {
            println!("ğŸ¤– Mock ì¶”ë¡  ì‹¤í–‰ ì¤‘... (ONNX ëª¨ë¸ ì—†ìŒ)");
            // Mock ì‘ë‹µ: ê°„ë‹¨í•œ ì•¡ì…˜ ê²°ì •
            let mock_response = "action: click, value: 1, reason: ìƒí’ˆ ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ ìƒì„¸ ì •ë³´ í™•ì¸";
            Ok(mock_response.to_string())
        }
    }
    
    // í–‰ë™ì„ ê²°ì •í•˜ëŠ” ë¶€ë¶„ - ê°„ë‹¨í•œ ì‘ë‹µ íŒŒì‹±
    pub async fn decide_browser_action(&self, llm_response: &str) -> Result<(String, i32, String)> {
        println!("ğŸ” Parsing LLM response: {}", llm_response);
        
        // "action: 1, reason: ìƒí’ˆ ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ ìƒì„¸ ì •ë³´ í™•ì¸" í˜•ì‹ íŒŒì‹±
        let response = llm_response.trim();
        let mut action = String::new();
        let mut value = 0i32;
        let mut reason = String::new();
        
        // ì½¤ë§ˆë¡œ ë¶„ë¦¬í•˜ì—¬ íŒŒì‹±
        for part in response.split(',') {
            let part = part.trim();
            
            if part.starts_with("action:") {
                action = part.replace("action:", "").trim().to_string();
            } else if part.starts_with("value:") || part.contains(':') && part.chars().filter(|c| c.is_numeric()).count() > 0 {
                // value: ìˆ«ì ë˜ëŠ” ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°
                if let Some(num_str) = part.split(':').nth(1) {
                    value = num_str.trim().parse().unwrap_or(0);
                } else if let Ok(parsed_num) = part.trim().parse::<i32>() {
                    value = parsed_num;
                }
            } else if part.starts_with("reason:") {
                reason = part.replace("reason:", "").trim().to_string();
            }
        }
        
        // ê¸°ë³¸ê°’ ì„¤ì •
        if action.is_empty() {
            action = "unknown".to_string();
        }
        if reason.is_empty() {
            reason = "No reason provided".to_string();
        }
        
        println!("âœ… Parsed - Action: {}, Value: {}, Reason: {}", action, value, reason);
        Ok((action, value, reason))
    }
    



    // Qwen 2.5 í† í¬ë‚˜ì´ì œì´ì…˜
    fn tokenize(&self, text: &str) -> Result<Vec<i64>> {
        let tokens = self.tokenizer.encode_with_special_tokens(text);
        Ok(tokens.into_iter().map(|t| t as i64).collect())
    }

    // í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    fn detokenize(&self, tokens: &[i64]) -> Result<String> {
        let u32_tokens: Vec<u32> = tokens.iter().map(|&t| t as u32).collect();
        let text = self.tokenizer.decode(u32_tokens)
            .map_err(|e| ErrorS::data("LocalLLM::detokenize", format!("Failed to decode tokens: {}", e)))?;
        Ok(text)
    }
    
    // ONNX ì¶œë ¥ì—ì„œ í† í° ì¶”ì¶œ
    fn extract_output_tokens(&self, output_value: &Value) -> Result<Vec<i64>> {
        // ONNX Valueì—ì„œ í† í° ë°°ì—´ ì¶”ì¶œ
        match output_value.try_extract::<i64>() {
            Ok(tensor) => {
                let tokens: Vec<i64> = tensor.view().iter().cloned().collect();
                
                // ìƒì„±ëœ í† í°ì—ì„œ íŠ¹ìˆ˜ í† í° ì œê±° ë° ê¸¸ì´ ì œí•œ
                let max_output_tokens = 100; // ì¶œë ¥ í† í° ì œí•œ
                let filtered_tokens: Vec<i64> = tokens
                    .into_iter()
                    .take(max_output_tokens)
                    .filter(|&token| token > 0 && token < 151936) // Qwen vocabulary ë²”ìœ„
                    .collect();
                
                if filtered_tokens.is_empty() {
                    // fallback: Mock ì‘ë‹µ í† í°í™”
                    let mock_text = "action: click, value: 1, reason: ì‘ë‹µ ìƒì„±";
                    self.tokenize(mock_text)
                } else {
                    Ok(filtered_tokens)
                }
            },
            Err(_) => {
                // íƒ€ì… ë³€í™˜ ì‹¤íŒ¨ì‹œ ë‹¤ë¥¸ íƒ€ì…ìœ¼ë¡œ ì‹œë„
                if let Ok(float_tensor) = output_value.try_extract::<f32>() {
                    // argmaxë¡œ í† í° ì„ íƒ (ê°„ë‹¨í•œ greedy decoding)
                    let logits = float_tensor.view();
                    let tokens: Vec<i64> = logits
                        .axis_iter(ndarray::Axis(0))
                        .map(|row| {
                            row.iter()
                                .enumerate()
                                .max_by(|a, b| a.1.partial_cmp(b.1).unwrap_or(std::cmp::Ordering::Equal))
                                .map(|(idx, _)| idx as i64)
                                .unwrap_or(0)
                        })
                        .take(50) // ìµœëŒ€ 50 í† í°
                        .collect();
                    
                    Ok(tokens)
                } else {
                    Err(ErrorS::data("LocalLLM::extract_output_tokens", "Failed to extract tokens from ONNX output"))
                }
            }
        }
    }
    
    // í† í° ê°œìˆ˜ ê³„ì‚°
    pub fn count_tokens(&self, text: &str) -> usize {
        self.tokenizer.encode_with_special_tokens(text).len()
    }
    
    // í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€ ê¸¸ì´ë¡œ ìë¥´ê¸°
    pub fn truncate_text(&self, text: &str, max_tokens: usize) -> String {
        let tokens = self.tokenizer.encode_with_special_tokens(text);
        if tokens.len() <= max_tokens {
            return text.to_string();
        }
        
        let truncated_tokens: Vec<u32> = tokens.into_iter().take(max_tokens).collect();
        self.tokenizer.decode(truncated_tokens).unwrap_or_else(|_| text.chars().take(max_tokens * 4).collect())
    }
    
    // ============ í”„ë¡¬í”„íŠ¸ ê´€ë ¨ í•¨ìˆ˜ë“¤ ============
    

    // ì‹¤ì œ HTML ë¶„ì„ ê¸°ë°˜ ì§€ëŠ¥í˜• ì‘ë‹µ ìƒì„±
    async fn generate_intelligent_response(&self, html: &str,main_url : &str, url : &str) -> Result<String> {
        // ë””ë²„ê¹…ì„ ìœ„í•´ í”„ë¡¬í”„íŠ¸ ì¼ë¶€ ì¶œë ¥
        println!("ğŸ” ì‹¤ì œ HTML ë¶„ì„ - í”„ë¡¬í”„íŠ¸ í‚¤ì›Œë“œ: {}",url);
        
        // HTML íƒ€ì… íŒë‹¨ì€ í•„ìš”ì‹œ ì¶”ê°€
        // let _judgment_html_type = self.judgment_html_type_proccessor(html, url);
        let response = self.main_browser_action_prompt(html,main_url,url);
        
        Ok(response)
    }

    // ì‚­ì œëœ ë©”ì„œë“œë“¤ (ë” ì´ìƒ í•„ìš” ì—†ìŒ)
    // parse_action_response - LLM ì‘ë‹µ íŒŒì‹± ë¶ˆí•„ìš”
    // create_browser_action_prompt - í”„ë¡¬í”„íŠ¸ ìƒì„± ë¶ˆí•„ìš”
    // create_product_check_prompt - ìƒí’ˆ ì²´í¬ í”„ë¡¬í”„íŠ¸ ë¶ˆí•„ìš”
    #[allow(dead_code)]
    fn main_browser_action_prompt(&self, html: &str,main_url : &str, url : &str) -> String {

        let site_prompt = match main_url{
            "https://www.coupang.com" => prompt_selector("ì¿ íŒ¡"),
            "https://www.11st.co.kr" => prompt_selector("11ë²ˆê°€"), 
            "https://www.amazon.com/" => prompt_selector("ì•„ë§ˆì¡´"),
            _ => "ì•Œ ìˆ˜ ì—†ëŠ” ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤".to_string()
        };
    format!(
        r#"

        ë‹¹ì‹ ì€ ì˜¨ë¼ì¸ ì‡¼í•‘ëª°ì˜ í• ì¸ ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜ì§‘í•˜ëŠ” ì „ë¬¸ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ëª©í‘œ: í• ì¸ ì •ë³´ê°€ ìˆì„ë§Œí•œ í˜ì´ì§€ë¡œ ë“¤ì–´ê°€ë„ë¡ url ê³¼ htmlì„ ë³´ê³  ì•¡ì…˜ íƒ€ì…ì„ ê²°ì •í•´ë¼

        ì‚¬ìš© ê°€ëŠ¥í•œ ë¸Œë¼ìš°ì € ì•¡ì…˜:
        - Navigate {{ url: "URL" }} : ìƒˆ í˜ì´ì§€ë¡œ ì´ë™
        - Click {{ selector: "CSSì…€ë ‰í„°" }} : ìš”ì†Œ í´ë¦­
        - Scroll {{ direction: "up/down", amount: í”½ì…€ìˆ˜ }} : í˜ì´ì§€ ìŠ¤í¬ë¡¤
        - ExtractText {{ selector: Some("CSSì…€ë ‰í„°") }} : í…ìŠ¤íŠ¸ ì¶”ì¶œ
        - WaitForElement {{ selector: "CSSì…€ë ‰í„°", timeout: ì´ˆ }} : ìš”ì†Œ ëŒ€ê¸°
        - FillForm {{ selector: "CSSì…€ë ‰í„°", value: "ì…ë ¥ê°’" }} : í¼ ì…ë ¥
        - ExecuteJs {{ script: "JavaScriptì½”ë“œ" }} : JS ì‹¤í–‰
        - GetPageState : í˜ì´ì§€ ìƒíƒœ í™•ì¸

        ## ì‡¼í•‘ëª° í• ì¸ í‚¤ì›Œë“œ:
        
        {}

        ì•¡ì…˜ ê²°ì • ë¡œì§:
        ```
        if (íŒì—…_ê°ì§€) â†’ Click(ë‹«ê¸°_ë²„íŠ¼)
        if (ë©”ì¸í˜ì´ì§€ && í• ì¸ë©”ë‰´_ì¡´ì¬) â†’ Navigate(í• ì¸ì„¹ì…˜)
        if (ëª©ë¡í˜ì´ì§€ && í• ì¸ìƒí’ˆ_ë§ìŒ) â†’ Click(ë”ë³´ê¸°/ì •ë ¬)
        if (í• ì¸ì •ë³´_ë°œê²¬) â†’ ExtractText(ìˆ˜ì§‘)
        if (ë¡œë”©ì¤‘) â†’ WaitForElement(ëŒ€ê¸°)
        if (í• ì¸í™•ì¥_ê°€ëŠ¥) â†’ Navigate/Click(í™•ì¥)
        ```

        ì‘ë‹µ í˜•ì‹ (JSON):
        {{
            "action": "ì•¡ì…˜íƒ€ì…",
            "params": {{ "íŒŒë¼ë¯¸í„°": "ê°’" }},
            "reason": "í• ì¸ ì •ë³´ ìˆ˜ì§‘ ê´€ì ì—ì„œì˜ ì„ íƒ ì´ìœ "
        }}

        ì˜ˆì‹œ:
        {{ "action": "Click", "params": {{ "selector": "button:contains('ë”ë³´ê¸°'), .load-more, .btn-more" }}, "reason": "ì¶”ê°€ í• ì¸ ìƒí’ˆì„ ë¡œë“œí•˜ì—¬ ë” ë§ì€ í• ì¸ ì •ë³´ ìˆ˜ì§‘" }}
        {{ "action": "Navigate", "params": {{ "url": "/event" }}, "reason": "ë©”ì¸í˜ì´ì§€ì˜ ì´ë²¤íŠ¸ ì„¹ì…˜ìœ¼ë¡œ ì´ë™í•˜ì—¬ í• ì¸ ì •ë³´ íƒìƒ‰" }}
        {{ "action": "ExtractText", "params": {{ "selector": ".price, .discount, .coupon, .shipping" }}, "reason": "ìƒí’ˆì˜ ê°€ê²©, í• ì¸ìœ¨, ì¿ í°, ë°°ì†¡ ì •ë³´ ë“± ëª¨ë“  í• ì¸ í˜œíƒ ì¶”ì¶œ" }}
        
        
        url : 
            {} 
        HTML:
            {}
       "#,
                url,html,site_prompt
            )
    }
    
    
}
// LLM ë©”ì„œë“œ ì¶”ê°€
impl LocalLLM {
    fn judgment_html_type_proccessor(&self, _html: &str, _url: &str) -> String {
        // HTML íƒ€ì… íŒë‹¨ ë¡œì§ (í•„ìš”ì‹œ êµ¬í˜„)
        "product_page".to_string()
    }
}

pub fn prompt_selector(site: &str) -> String {
    match site {
        "ì¿ íŒ¡" => format!(r#"
            **ì¿ íŒ¡:**
            í• ì¸: "íŒë§¤ìíŠ¹ê°€", "ì¿ í°ê°€", "ì¦‰ì‹œí• ì¸", "íƒ€ì„ë”œ", "ì˜¤ëŠ˜ì˜ë°œê²¬", "%í• ì¸", "%OFF"
            ë°°ì†¡: "ë¡œì¼“ë°°ì†¡", "ë¬´ë£Œë°°ì†¡", "ë‹¹ì¼ë°°ì†¡", "ìƒˆë²½ë°°ì†¡"
            ì ë¦½: "ì¿ íŒ¡ìºì‹œ", "ì ë¦½", "%ì ë¦½"
            ë©¤ë²„ì‹­: "ì™€ìš°ë©¤ë²„ì‹­", "ì™€ìš°í• ì¸", "íšŒì›ì „ìš©"
            ë¬¶ìŒ: "ëŒ€ìš©ëŸ‰í• ì¸", "ë¬¶ìŒë°°ì†¡", "ì„¸íŠ¸ìƒí’ˆ", "1+1", "2+1"
            ì¶”ê°€: ê³„ì ˆë³„ ì¶•ì œë³„ ê³µíœ´ì¼ë³„ ì¶”ê°€ì ì¸ í• ì¸ í˜ì´ì§€ê°€ ì¡´ì¬í•¨

            í–‰ë™ ì§€ì¹¨:
            ### 1ë‹¨ê³„: ì§„ì… ì¥ë²½ ì œê±°
            âœ… íŒì—…/ëª¨ë‹¬ ê°ì§€ â†’ Clickìœ¼ë¡œ ì œê±°
            - "ë™ì˜", "í™•ì¸", "Ã—", "ë‹«ê¸°", "Accept", "OK" ë²„íŠ¼
            - ì•± ì„¤ì¹˜ ìœ ë„ â†’ "ì›¹ì—ì„œ ê³„ì†", "ë‚˜ì¤‘ì—" ì„ íƒ

            ### 2ë‹¨ê³„: í˜ì´ì§€ íƒ€ì…ë³„ ì „ëµ
            ğŸ  **ë©”ì¸í˜ì´ì§€** (ë„ë©”ì¸ ë£¨íŠ¸)
            â†’ í• ì¸ ë©”ë‰´/ë°°ë„ˆ ì°¾ê¸° â†’ Navigate
            - ê° ì‚¬ì´íŠ¸í¼ í• ì¸ ì´ë²¤íŠ¸ ë° í• ì¸ Page íƒìƒ‰

            ğŸª **ëª©ë¡/ì¹´í…Œê³ ë¦¬ í˜ì´ì§€**
            â†’ ì •ë ¬ ë° í™•ì¥ â†’ Click/Scroll
            - "í• ì¸ìœ¨ìˆœ", "ê°€ê²©ë‚®ì€ìˆœ" ì •ë ¬
            - "ë”ë³´ê¸°", "ë‹¤ìŒí˜ì´ì§€" í™•ì¥

            ğŸ›ï¸ **ìƒí’ˆ ìƒì„¸í˜ì´ì§€**
            â†’ ëª¨ë“  í• ì¸ ì •ë³´ ìˆ˜ì§‘ â†’ ExtractText
            - ê°€ê²©, í• ì¸ìœ¨, ì¿ í°, ì ë¦½, ë°°ì†¡ í˜œíƒ

            ### 3ë‹¨ê³„: í• ì¸ ì •ë³´ ìš°ì„  íƒì§€
            ğŸš¨ **ê¸´ê¸‰ë„ ë†’ìŒ** (ì¦‰ì‹œ ExtractText):
            - "ì˜¤ëŠ˜ë§Œ", "ì‹œê°„í•œì •", "ë§ˆê°ì„ë°•", "ì„ ì°©ìˆœ", "í•œì •ìˆ˜ëŸ‰"
            - 30% ì´ìƒ ê³ í• ì¸ìœ¨
            - "íƒ€ì„ë”œ", "í”Œë˜ì‹œì„¸ì¼", "ê¹œì§í• ì¸"

            ğŸ“Š **í™•ì¥ íƒìƒ‰** (ë” ë§ì€ í• ì¸):
            - í• ì¸ ìƒí’ˆ 10ê°œ ì´ìƒ â†’ "ë”ë³´ê¸°" Click
            - ë¬´í•œìŠ¤í¬ë¡¤ â†’ Scroll (down, 500-1000px)
            - ì¶”ê°€ ìƒí’ˆ ë¡œë”© ì‹œ
            - í˜ì´ì§€ë„¤ì´ì…˜ â†’ ë‹¤ìŒ í˜ì´ì§€ Click
            - ë‹¤ë¥¸ í• ì¸ ì¹´í…Œê³ ë¦¬ â†’ Navigate

            ### 4ë‹¨ê³„: ë™ì  ì²˜ë¦¬
            ğŸ”„ **ë¡œë”© ìƒíƒœ** â†’ WaitForElement (5-10ì´ˆ)
            - "ë¡œë”©", "ê°€ê²© í™•ì¸ ì¤‘", "í˜œíƒ ê³„ì‚° ì¤‘", ìŠ¤í”¼ë„ˆ

        "#),
        "11ë²ˆê°€" => format!(r#"
            **11ë²ˆê°€:**
            í• ì¸: "ì˜¤ëŠ˜íŠ¹ê°€", "íƒ€ì„íŠ¹ê°€", "11ë²ˆê°€íŠ¹ê°€", "ë¬´ë£Œë°°ì†¡", "ë‹¹ì¼ë°°ì†¡"
            í˜œíƒ: "í¬ì¸íŠ¸ì ë¦½", "ë§ˆì¼ë¦¬ì§€", "ìºì‹œë°±", "ë©¤ë²„ì‹­í• ì¸"
        "#),
        _ => format!("ê¸°ë³¸ í”„ë¡¬í”„íŠ¸")
    }
}
// LLMRepository alias for compatibility
pub type LLMRepository = LocalLLM;
